

# CODE TO CLASSIFY IMAGES (CIFAR-10) USING CNNs



# STEP 0: PROBLEM STATEMENT
- CIFAR-10 is a dataset that consists of several images divided into the following 10 classes:
    - Airplanes
    - Cars
    - Birds
    - Cats
    - Deer
    - Dogs
    - Frogs
    - Horses
    - Ships
    - Trucks

- The dataset stands for the Canadian Institute For Advanced Research (CIFAR)
- CIFAR-10 is widely used for machine learning and computer vision applications.
- The dataset consists of 60,000 32x32 color images and 6,000 images of each class.
- Images have low resolution (32x32).
- Data Source: https://www.cs.toronto.edu/~kriz/cifar.html

# STEP #1: IMPORT LIBRARIES/DATASETS
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn
from keras.datasets import cifar10
(X_train, y_train) , (X_test, y_test) = cifar10.load_data()
X_train.shape
X_test.shape
y_train.shape
y_test.shape
# STEP #2: VISUALIZE DATA
i = 29009
plt.imshow(X_train[i])
print(y_train[i])
# STEP #3: DATA PREPARATION
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
number_cat = 10
y_train
import keras
y_train = keras.utils.to_categorical(y_train, number_cat)
y_train
y_test = keras.utils.to_categorical(y_test, number_cat)
y_test
X_train = X_train/255
X_test = X_test/255

X_train
X_train.shape
Input_shape = X_train.shape[1:]
Input_shape
# STEP #4: TRAIN THE MODEL
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, Dropout
from keras.optimizers import Adam
from keras.callbacks import TensorBoard
cnn_model = Sequential()
cnn_model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', input_shape = Input_shape))
cnn_model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))
cnn_model.add(MaxPooling2D(2,2))
cnn_model.add(Dropout(0.4))


cnn_model.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))
cnn_model.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))
cnn_model.add(MaxPooling2D(2,2))
cnn_model.add(Dropout(0.4))

cnn_model.add(Flatten())

cnn_model.add(Dense(units = 1024, activation = 'relu'))

cnn_model.add(Dense(units = 1024, activation = 'relu'))

cnn_model.add(Dense(units = 10, activation = 'softmax'))
cnn_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
history = cnn_model.fit(X_train, y_train, batch_size = 32, epochs = 5, shuffle = True)
# STEP #5: EVALUATE THE MODEL
evaluation = cnn_model.evaluate(X_test, y_test)
print('Test Accuracy: {}'.format(evaluation[1]))
predicted_probabilities = cnn_model.predict(X_test)
predicted_classes = np.argmax(predicted_probabilities, axis=1)
predicted_classes.size()
y_test = y_test.argmax(1)
y_test
L = 7
W = 7
fig, axes = plt.subplots(L, W, figsize = (12, 12))
axes = axes.ravel()

for i in np.arange(0, L*W):
    axes[i].imshow(X_test[i])
    axes[i].set_title('Prediction = {}\n True = {}'.format(predicted_classes[i], y_test[i]))
    axes[i].axis('off')

plt.subplots_adjust(wspace = 1)
